{
    "train_data_path": "~/data/qanta/2018/qanta.train.2018.04.18.json",
    "validation_data_path": "~/data/qanta/2018/qanta.dev.2018.04.18.json",
    "dataset_reader": {
        "type": "quizbowl",
        "tokenizer": {
            "type": "transformer",
            "model_name": "roberta-base",
            "max_length": 64
        },
        "token_indexers": {
            "tokens": {
                "type": "transformer",
                "model_name": "roberta-base"
            }
        },
        "text_unit": "sentence"
    },
    "validation_dataset_reader": {
        "type": "quizbowl",
        "tokenizer": {
            "type": "transformer",
            "model_name": "roberta-base",
            "max_length": 512
        },
        "token_indexers": {
            "tokens": {
                "type": "transformer",
                "model_name": "roberta-base"
            }
        },
        "text_unit": "question"
    },
    "vocabulary": {
        "directory_path": "work/coling2020/vocab/vocabulary"
    },
    "model": {
        "type": "quizbowl_guesser",
        "text_field_embedder": {
            "token_embedders": {
                "tokens": {
                    "type": "transformer",
                    "model_name": "roberta-base"
                }
            },
            "allow_unmatched_keys": true
        },
        "text_encoder": {
            "type": "transformer",
            "pooling_type": "first",
            "input_dim": 768,
            "output_dim": 300,
            "do_projection": true
        },
        "entity_embedder": {
            "type": "embedding",
            "vocab_namespace": "entities",
            "embedding_dim": 300,
            "pretrained_file": "work/coling2020/wikipedia2vec/enwiki_20180420_300d_entity.txt.bz2"
        },
        "dropout_encodings": 0.1
    },
    "iterator": {
        "type": "bucket",
        "sorting_keys": [["tokens", "num_tokens"]],
        "batch_size": 128
    },
    "validation_iterator": {
        "type": "bucket",
        "sorting_keys": [["tokens", "num_tokens"]],
        "batch_size": 32
    },
    "trainer": {
        "optimizer": {
            "type": "adam_w",
            "parameter_groups": [
                [["bias", "LayerNorm.weight"], {"weight_decay": 0.0}],
                [["entity_embedder"], {"lr": 2e-4}]
            ],
            "lr": 1e-4,
            "weight_decay": 0.01,
            "correct_bias": false
        },
        "learning_rate_scheduler": {
            "type": "slanted_triangular",
            "num_epochs": 10,
            "num_steps_per_epoch": 4593,
            "cut_frac": 0.1
        },
        "grad_norm": 1.0,
        "num_epochs": 10,
        "patience": 3,
        "cuda_device": [0],
        "validation_metric": "+mrr",
        "num_serialized_models_to_keep": 1
    }
}
